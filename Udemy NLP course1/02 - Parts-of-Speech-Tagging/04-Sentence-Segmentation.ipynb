{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "215f566a-cbd3-4a4c-b023-34b8b3920aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05f7bf98-4823-47cc-92e1-8b9b1c8aa42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc= nlp('This is the first sentence. This is another sentence. This is the last sentence.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55d31022-09cb-4ce5-9e65-6fa1b58bd1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is\n"
     ]
    }
   ],
   "source": [
    "print(doc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ddca3f7-e36a-42fd-bc82-cf06ea723aee",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msents\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;66;03m#---> error because it is a generator unlike just doc[1] it will not give results\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "print(doc.sents[1]) #---> error because it is a generator unlike just doc[1] it will not give results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5823de89-d88e-4a1b-982c-72394cf055eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_sents = [sent for sent in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b181fdf-d7f6-4cb6-a5c6-8095fa334f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is another sentence.\n"
     ]
    }
   ],
   "source": [
    "print(doc_sents[1])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cc20aeb6-d323-49a4-9568-a195c71c5638",
   "metadata": {},
   "source": [
    "Sents are Span\n",
    "\n",
    "At first it looks like each sent conatins text from the Original Doc object. In fact they are just Span with start and end token pointers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7617d2ea-8ff4-4219-a6f5-f5c3dcd5651e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc_sents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7174c8b3-866a-44c1-8f5a-c60351e989f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 11\n"
     ]
    }
   ],
   "source": [
    "print(doc_sents[1].start, doc_sents[1].end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567c80a9-6226-4a26-935e-10d7bd7c77a1",
   "metadata": {},
   "source": [
    "## Adding Rules"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ba50cf9f-1dd3-44cd-b916-7281a11e56a7",
   "metadata": {},
   "source": [
    "Spacy's built in sentencizer relies on dependency parse and end-of-sentence punctuation to determine segmentation rules. We can add rules of our own, but they have to be added before the creation of Doc object, as that is where the parsing of segment start tokens happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ce7da5d-ef85-4811-b1b4-0559b3c7ecae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True This\n",
      "False is\n",
      "False a\n",
      "False sentence\n",
      "False .\n",
      "True This\n",
      "False is\n",
      "False a\n",
      "False sentence\n",
      "False .\n",
      "True This\n",
      "False is\n",
      "False a\n",
      "False sentence\n",
      "False .\n"
     ]
    }
   ],
   "source": [
    "# Parsing the segmentation start tokens happens during nlp pipeline\n",
    "doc = nlp('This is a sentence. This is a sentence. This is a sentence.')\n",
    "\n",
    "for token in doc:\n",
    "    print(token.is_sent_start, token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ae31a66-f5b5-4739-870c-9628f247dc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Management is doing things right; leadership is doing the right things.\"\n",
      "-Peter Drucker\n"
     ]
    }
   ],
   "source": [
    "# SPACY's DEFAULT BEHAVIOR\n",
    "doc = nlp('\"Management is doing things right; leadership is doing the right things.\" -Peter Drucker')\n",
    "\n",
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4a101fe-cb8d-46c4-b3a4-463232d671b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "Management\n",
      "is\n",
      "doing\n",
      "things\n",
      "right\n",
      ";\n",
      "leadership\n",
      "is\n",
      "doing\n",
      "the\n",
      "right\n",
      "things\n",
      ".\n",
      "\"\n",
      "-Peter\n"
     ]
    }
   ],
   "source": [
    "for token in doc[:-1]:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "519a25df-7730-420a-9b0c-43cb7df5d1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d29530b7-2daf-410f-8176-fb590ec2464f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This \n",
      "is This\n",
      "a This is\n",
      "sentence This is a\n",
      ". This is a sentence\n",
      "This This is a sentence.\n",
      "is This is a sentence. This\n",
      "a This is a sentence. This is\n",
      "sentence This is a sentence. This is a\n",
      ". This is a sentence. This is a sentence\n",
      "This This is a sentence. This is a sentence.\n",
      "is This is a sentence. This is a sentence. This\n",
      "a This is a sentence. This is a sentence. This is\n",
      "sentence This is a sentence. This is a sentence. This is a\n",
      ". This is a sentence. This is a sentence. This is a sentence\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token, doc[0:token.i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2467ea1-4462-4f46-a332-602e5ef708a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from span we can get the start and end index\n",
    "for span in doc.ents:\n",
    "    print(span.start, span.end) #----> check once writing notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4722413-1c73-4306-966d-05804042e280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec',\n",
       " 'tagger',\n",
       " 'set_custom_boundaries',\n",
       " 'parser',\n",
       " 'attribute_ruler',\n",
       " 'lemmatizer',\n",
       " 'ner']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a new rule to the pipeline\n",
    "from spacy.language import Language\n",
    "@Language.component(\"set_custom_boundaries\")\n",
    "def set_custom_boundaries(doc):\n",
    "    for token in doc[:-1]:\n",
    "        if token.text==\";\":\n",
    "            doc[token.i+1].is_sent_start = True\n",
    "    return doc\n",
    "\n",
    "nlp.add_pipe(\"set_custom_boundaries\",before=\"parser\")\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "43841e0a-90c4-4a78-849e-1652563f32a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Management is doing things right;\n",
      "leadership is doing the right things.\"\n",
      "-Peter Drucker\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('\"Management is doing things right; leadership is doing the right things.\" -Peter Drucker')\n",
    "\n",
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2871e746-ed52-4303-9a20-bf56ab8302c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E043] Refusing to write to token.sent_start if its document is parsed, because this may cause inconsistent state.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdoc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_sent_start\u001b[49m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\tokens\\token.pyx:528\u001b[0m, in \u001b[0;36mspacy.tokens.token.Token.is_sent_start.__set__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: [E043] Refusing to write to token.sent_start if its document is parsed, because this may cause inconsistent state."
     ]
    }
   ],
   "source": [
    "doc[7].is_sent_start= True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753f1532-ec99-4b63-9c4d-8c297b494edb",
   "metadata": {},
   "source": [
    "After passing the sentence we cannot set the sentence to true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b308f002-1ab2-4701-953e-5149fc0c6df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"This is a sentence. This is \\n another\\n. This is \\n\\n one more.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4f9bff9a-5d44-47dd-951f-ffeca26da4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'sentence', '.']\n",
      "['This', 'is', '\\n ', 'another', '\\n', '.']\n",
      "['This', 'is', '\\n\\n ', 'one', 'more', '.']\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    print([token.text for token in sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8cff473a-3082-4099-aff6-d8b52d59523e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doubt.. once look into the notebook which is provided by tutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e5bf86-3635-432a-8d83-87ed0faed665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
